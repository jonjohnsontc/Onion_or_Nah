{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_model_test\n",
    "\n",
    "**Description:** Using the production logarithmic model to predict on unseen headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Vectorizer, Model, and New Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/new_content.csv', 'rb') as f:\n",
    "    df = pd.read_csv(f)\n",
    "with open('../pickle/tfidf_2.pkl', 'rb') as f:\n",
    "    tfidif_2 = pickle.load(f)\n",
    "with open('../pickle/log_model.pkl', 'rb') as f:\n",
    "    log_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examining New Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTA Official Too Nervous To Tell Commuters Waiting For Train That Service Shut Down Permanently An Hour Ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‘Rock The Caliphate’ Charity Concert Features U2, Ed Sheeran, Dua Lipa Coming Together To Raise Money For Struggling Islamic State</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deformed, Half-Feathered Audubon Society President Flees Into Forest After Injecting Self With Bird DNA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Study Confirms This Didn’t Even Feel Like A 4-Day Work Week</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cory Booker Expelled From Senate, Stripped Naked, Forced To Wander Maryland Bog In Woe For All Eternity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fox Business Host Calls Former President George W. Bush a 'Radical' Liberal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian State Media Accuses Anime of Promoting Child Suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dangerous drug trend called 'wasping' combines insecticide with meth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nokia 9 Smartphone Packing Five Rear Camera Lens Image Leaked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'Remodelling the lizard people's lair': Denver airport trolls conspiracy theorists</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                title  \\\n",
       "0                         MTA Official Too Nervous To Tell Commuters Waiting For Train That Service Shut Down Permanently An Hour Ago   \n",
       "1  ‘Rock The Caliphate’ Charity Concert Features U2, Ed Sheeran, Dua Lipa Coming Together To Raise Money For Struggling Islamic State   \n",
       "2                             Deformed, Half-Feathered Audubon Society President Flees Into Forest After Injecting Self With Bird DNA   \n",
       "3                                                                     New Study Confirms This Didn’t Even Feel Like A 4-Day Work Week   \n",
       "4                             Cory Booker Expelled From Senate, Stripped Naked, Forced To Wander Maryland Bog In Woe For All Eternity   \n",
       "5                                                         Fox Business Host Calls Former President George W. Bush a 'Radical' Liberal   \n",
       "6                                                                        Russian State Media Accuses Anime of Promoting Child Suicide   \n",
       "7                                                                Dangerous drug trend called 'wasping' combines insecticide with meth   \n",
       "8                                                                       Nokia 9 Smartphone Packing Five Rear Camera Lens Image Leaked   \n",
       "9                                                  'Remodelling the lizard people's lair': Denver airport trolls conspiracy theorists   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_mat = tfidif_2.transform(df['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting on New Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5455661 , 0.4544339 ],\n",
       "       [0.73684455, 0.26315545],\n",
       "       [0.77122721, 0.22877279],\n",
       "       [0.95058404, 0.04941596],\n",
       "       [0.84775819, 0.15224181],\n",
       "       [0.65895784, 0.34104216],\n",
       "       [0.29002262, 0.70997738],\n",
       "       [0.27191088, 0.72808912],\n",
       "       [0.4416558 , 0.5583442 ],\n",
       "       [0.44680134, 0.55319866]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.predict_proba(term_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.predict(term_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: I'm impressed with 90% accuracy on this new sample, though I suppose it's not out of the realm of possibility with a test accuracy of ~81.7%. I should even expect a random new sample to perform like this every so often. \n",
    "\n",
    "Even from a glance, it's easy to see that each one of the above new headlines is similar to the one's that I built my model with. At least in the sense that the Onion headlines are much more verbose. Part of me wonders whether the length of headline strongly influences the prediction, given the difference in average character length between Onion and non-Onion posts. Unfortunately, I don't know enough about how vectorizers work to know if that contributed to each TFIDF component measure, however, I would like to take some time in the future to study this and find out.\n",
    "\n",
    "I would be interested to know what factors contributed to the one incorrect new prediction that my model made. Part of me thinks that a term like \"Fox\" would appear far more often within the Onion posts, as the news source is frequently poked fun at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: In conclusion, I'm very confident that this model can be used to accurately differentiate between Satirical and Sensational headlines (so as long as those Satirical headlines come from the Onion). That being stated, I do think it will be worthwhile to eventually try and refine this model, by increasing the scrutiny of the preprocessing step through the following:\n",
    "\n",
    "- Removing “American Voices” headlines from The Onion (these headlines are worded more similarly to Sensational headlines, in terms of their length). \n",
    "- Consider increasing ngram range to (1, 3)\n",
    "- Further tuning the Random Forest hyperparameters\n",
    "- Lemmatize the dataset\n",
    "- Consider tuning SVD to eliminate fewer features\n",
    "- Apply SVD to the multi-ngram vector\n",
    "\n",
    "Nonetheless, I'm happy with how the model turned out, and I'm excited to start using this in the field."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
